{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T22:33:14.362008200Z",
     "start_time": "2025-02-04T22:33:13.614963700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터 : ../CM1/data/csvdata/opencv_train.csv\n",
      "테스트 데이터 : ../CM1/data/csvdata/opencv_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "import string\n",
    "\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "p_list = ['facebook', 'tensorflow', 'microsoft', 'bitcoin','opencv',\n",
    "          'ansible','flutter','kubernetes','roslyn','typescript', 'dartlang','integrate']\n",
    "project_name = 'opencv'\n",
    "Clean_Method = \"CM1\"\n",
    "# checkpoint = 225\n",
    "# in : 2475\n",
    "checkpoint = 225\n",
    "# checkpoint = 750\n",
    "\n",
    "train_data = pd.read_csv('../'+Clean_Method+'/data/csvdata/'+project_name+'_train.csv')\n",
    "test_data = pd.read_csv('../'+Clean_Method+'/data/csvdata/'+project_name+'_test.csv')\n",
    "\n",
    "print('train data : ../'+Clean_Method+'/data/csvdata/'+project_name+'_train.csv')\n",
    "print('test data : ../'+Clean_Method+'/data/csvdata/'+project_name+'_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T22:33:14.372008600Z",
     "start_time": "2025-02-04T22:33:14.363011200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 6)\n",
      "(300, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_TOKEN']=\"API_KEY\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T22:33:14.373008Z",
     "start_time": "2025-02-04T22:33:14.368007600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T22:33:14.376009100Z",
     "start_time": "2025-02-04T22:33:14.372008600Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T22:33:21.038407Z",
     "start_time": "2025-02-04T22:33:14.380003800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version 2.2.2\n",
      "working on cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"pytorch version {torch.__version__}\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"working on {device}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T22:33:21.048402100Z",
     "start_time": "2025-02-04T22:33:21.040405200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T22:33:21.057399400Z",
     "start_time": "2025-02-04T22:33:21.048402100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "   \n",
    "def generate_test_prompt(data_point):\n",
    "      return f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> GitHub Issue Report Classifier <|eot_id|><|start_header_id|>user<|end_header_id|> Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\"+str(data_point[\"content\"])+\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\".strip()\n",
    "\n",
    "\n",
    "X_test = pd.DataFrame(test_data.apply(generate_test_prompt, axis=1), columns=[\"text\"])\n",
    "\n",
    "y_true = test_data.label\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T22:33:21.097403100Z",
     "start_time": "2025-02-04T22:33:21.053399800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels =  [\"bug\", \"feature\", \"question\"]\n",
    "    mapping = {'question': 2, 'feature': 1, 'bug': 0}\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "    \n",
    "    y_true = np.vectorize(map_func)(y_true)\n",
    "    y_pred = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true)) \n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
    "        \n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "    print(project_name)\n",
    "    print('\\nClassification Report:')\n",
    "    \n",
    "    # file_name = \"../CM1/result/metric/epoch3/\"+project_name+\"_\"+str(checkpoint)+\"_cm.txt\"\n",
    "    file_name = \"../CM1/result/metric/\"+project_name+\"_\"+str(checkpoint)+\"_cm.txt\"\n",
    "    with open(file_name, \"w\") as text_file:\n",
    "        print(classification_report(y_true, y_pred, digits=4), file=text_file)\n",
    "    \n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2])\n",
    "    print('\\nConfusion Matrix:')\n",
    "\n",
    "    print(conf_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T22:33:21.102402700Z",
     "start_time": "2025-02-04T22:33:21.068404500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 이름: ../CM1/model/epoch3/opencv-llama-classifier/checkpoint-225\n",
      "토크나이저 이름: ../CM1/model/epoch3/opencv-llama-classifier/checkpoint-225\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e839ed1b77404a70af38a9fe0f3b8935"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model_name = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
    "model_name=\"../CM1/model/epoch3/\"+project_name+\"-llama-classifier/checkpoint-\"+str(checkpoint)   \n",
    "token_name=\"../CM1/model/epoch3/\"+project_name+\"-llama-classifier/checkpoint-\"+str(checkpoint)     \n",
    "\n",
    "\n",
    "\n",
    "print(\"model 이름: \"+model_name)\n",
    "print(\"토크나이저 이름: \"+token_name)\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device,\n",
    "    torch_dtype=compute_dtype,\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "max_seq_length = 1024 #2048\n",
    "tokenizer = AutoTokenizer.from_pretrained(token_name, max_seq_length=max_seq_length)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T22:33:42.976843100Z",
     "start_time": "2025-02-04T22:33:21.075407800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def predict(X_test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    y_answer = []\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        try:\n",
    "            prompt = X_test.iloc[i][\"text\"]\n",
    "            pipe = pipeline(task=\"text-generation\", \n",
    "                            model=model, \n",
    "                            tokenizer=tokenizer, \n",
    "                            max_new_tokens = 1, \n",
    "                            temperature = 0.1,\n",
    "                            # 여기\n",
    "                        )\n",
    "            result = pipe(prompt)\n",
    "            answer = result[0]['generated_text'].split(\"<|end_header_id|>\")[-1]\n",
    "            y_answer.append(answer)\n",
    "            if \"question\" in answer:\n",
    "                y_pred.append(\"question\")\n",
    "            elif \"feature\" in answer:\n",
    "                y_pred.append(\"feature\")\n",
    "            elif \"bug\" in answer:\n",
    "                y_pred.append(\"bug\")\n",
    "            else: \n",
    "                y_pred.append(\"empty\")\n",
    "                # print(result)\n",
    "        except Exception as e:\n",
    "            # print(len(tokenizer(X_test.iloc[i][\"text\"])['input_ids']))\n",
    "            y_pred.append(\"empty\")\n",
    "            y_answer.append('empty')\n",
    "            # print(e)\n",
    "            # print('bug')\n",
    "  \n",
    "    return y_pred, y_answer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T22:33:42.987843600Z",
     "start_time": "2025-02-04T22:33:42.983850400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, \n",
    "                             recall_score, \n",
    "                             precision_score, \n",
    "                             f1_score)\n",
    "\n",
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "\n",
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T22:33:42.995845Z",
     "start_time": "2025-02-04T22:33:42.991849600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:12<00:00,  4.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.770\n",
      "Accuracy for label 0: 0.450\n",
      "Accuracy for label 1: 0.900\n",
      "Accuracy for label 2: 0.960\n",
      "opencv\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "Confusion Matrix:\n",
      "[[45 27 28]\n",
      " [ 0 90 10]\n",
      " [ 3  1 96]]\n",
      "opencv\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred, y_answer= predict(X_test, model, tokenizer)\n",
    "result=evaluate(y_true, y_pred)\n",
    "print(project_name)\n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T22:34:55.923892600Z",
     "start_time": "2025-02-04T22:33:42.996851400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T22:34:55.947892Z",
     "start_time": "2025-02-04T22:34:55.928891700Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame({'text': X_test[\"text\"], \n",
    "                           'y_true':y_true, \n",
    "                           'y_pred': y_pred, \n",
    "                            'y_answer': y_answer},\n",
    "                         )\n",
    "evaluation.to_csv(\"../CM1/result/metric/predict/\"+project_name+\"_\"+str(checkpoint)+\"_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text   y_true    y_pred  \\\n",
      "0    <|begin_of_text|><|start_header_id|>system<|en...      bug  question   \n",
      "1    <|begin_of_text|><|start_header_id|>system<|en...      bug  question   \n",
      "2    <|begin_of_text|><|start_header_id|>system<|en...      bug       bug   \n",
      "3    <|begin_of_text|><|start_header_id|>system<|en...      bug  question   \n",
      "4    <|begin_of_text|><|start_header_id|>system<|en...      bug  question   \n",
      "..                                                 ...      ...       ...   \n",
      "295  <|begin_of_text|><|start_header_id|>system<|en...  feature   feature   \n",
      "296  <|begin_of_text|><|start_header_id|>system<|en...  feature   feature   \n",
      "297  <|begin_of_text|><|start_header_id|>system<|en...  feature   feature   \n",
      "298  <|begin_of_text|><|start_header_id|>system<|en...  feature   feature   \n",
      "299  <|begin_of_text|><|start_header_id|>system<|en...  feature   feature   \n",
      "\n",
      "     y_answer  \n",
      "0    question  \n",
      "1    question  \n",
      "2         bug  \n",
      "3    question  \n",
      "4    question  \n",
      "..        ...  \n",
      "295   feature  \n",
      "296   feature  \n",
      "297   feature  \n",
      "298   feature  \n",
      "299   feature  \n",
      "\n",
      "[300 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(evaluation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T22:34:55.956892300Z",
     "start_time": "2025-02-04T22:34:55.950899900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T22:34:55.960892700Z",
     "start_time": "2025-02-04T22:34:55.957893400Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: playsound in c:\\users\\hje\\anaconda3\\envs\\icpc-llama-v2\\lib\\site-packages (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install playsound"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T22:34:58.154206900Z",
     "start_time": "2025-02-04T22:34:55.962892600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T22:34:58.159207400Z",
     "start_time": "2025-02-04T22:34:58.155208500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICPC-llama-V2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
