{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-04T23:40:30.927871600Z",
     "start_time": "2025-02-04T23:40:30.211812500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터 : ../CM1/data/csvdata/flutter_train.csv\n",
      "테스트 데이터 : ../CM1/data/csvdata/flutter_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# tensorflow kubernetes\n",
    "p_list = ['facebook', 'tensorflow', 'microsoft', 'bitcoin','opencv',\n",
    "          'ansible','flutter','kubernetes','roslyn','typescript', 'dartlang','integrate']\n",
    "project_name = 'flutter'\n",
    "Clean_Method = \"CM1\"\n",
    "\n",
    "\n",
    "# Loading data from CSV files\n",
    "train_data = pd.read_csv('../'+Clean_Method+'/data/csvdata/'+project_name+'_train.csv')\n",
    "test_data = pd.read_csv('../'+Clean_Method+'/data/csvdata/'+project_name+'_test.csv')\n",
    "\n",
    "print('학습데이터 : ../'+Clean_Method+'/data/csvdata/'+project_name+'_train.csv')\n",
    "print('테스트 데이터 : ../'+Clean_Method+'/data/csvdata/'+project_name+'_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d00691b90d394127",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T23:40:30.957871400Z",
     "start_time": "2025-02-04T23:40:30.927871600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 6)\n",
      "(300, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d1f490df3706e7b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T23:40:34.425129200Z",
     "start_time": "2025-02-04T23:40:30.932869200Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_TOKEN']=\"API_KEY",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\")\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aed3f61c234ad1d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T23:40:34.426129100Z",
     "start_time": "2025-02-04T23:40:34.418128500Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e035079d9cf91",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T23:40:37.288338500Z",
     "start_time": "2025-02-04T23:40:34.425129200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f87742c237b3af56",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T23:40:37.292342700Z",
     "start_time": "2025-02-04T23:40:37.288338500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version 2.2.2\n",
      "working on cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"pytorch version {torch.__version__}\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"working on {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303a13884f513a54",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T23:40:37.304342300Z",
     "start_time": "2025-02-04T23:40:37.294342300Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dad09d9879b6fff2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T23:40:37.389350100Z",
     "start_time": "2025-02-04T23:40:37.312343100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 1)\n",
      "(300,)\n",
      "(300, 1)\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 300\n",
      "})\n",
      "                                                text\n",
      "0  <|begin_of_text|><|start_header_id|>system<|en...\n",
      "1  <|begin_of_text|><|start_header_id|>system<|en...\n",
      "                                                text\n",
      "0  <|begin_of_text|><|start_header_id|>system<|en...\n",
      "1  <|begin_of_text|><|start_header_id|>system<|en...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_prompt(data_point):\n",
    "    return f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> GitHub Issue Report Classifier<|eot_id|><|start_header_id|>user<|end_header_id|>\"+str(data_point[\"content\"]) +\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"+str(data_point[\"label\"])+\"<|eot_id|>\".strip()\n",
    "    # return f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> GitHub Issue Report Classifier <|eot_id|><|start_header_id|>user<|end_header_id|> Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\"+str(data_point[\"content\"])+\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\"+str(data_point[\"label\"])+\"<|eot_id|><|end_of_text|>\".strip()\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "def generate_test_prompt(data_point):\n",
    "     return f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> GitHub Issue Report Classifier<|eot_id|><|start_header_id|>user<|end_header_id|>\"+str(data_point[\"content\"])+\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\".strip()\n",
    "      # return f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> GitHub Issue Report Classifier <|eot_id|><|start_header_id|>user<|end_header_id|> Classify, IN ONLY 1 WORD, the following GitHub issue as 'feature', 'bug', or 'question' based on its title and body:\"+str(data_point[\"content\"])+\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\".strip()\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(train_data.apply(generate_prompt, axis=1), \n",
    "                       columns=[\"text\"])\n",
    "\n",
    "\n",
    "\n",
    "y_true = test_data.label\n",
    "X_test = pd.DataFrame(test_data.apply(generate_test_prompt, axis=1), columns=[\"text\"])\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_true.shape)\n",
    "print(X_test.shape)\n",
    "print(train_data)\n",
    "\n",
    "print(X_train.head(2))\n",
    "print(X_test.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b22f8f4fc113600",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T23:40:37.390350500Z",
     "start_time": "2025-02-04T23:40:37.341346100Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels =  [\"bug\", \"feature\", \"question\"]\n",
    "    mapping = {'question': 2, 'feature': 1, 'bug': 0}\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "    \n",
    "    y_true = np.vectorize(map_func)(y_true)\n",
    "    y_pred = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true)) \n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
    "        \n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2])\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    df = pd.DataFrame(conf_matrix)  # 열 이름 (예측 값)\n",
    "# CSV 파일로 저장\n",
    "#     df.to_csv(\"../CM1/result/\"+project_name+\"_confusion_matrix.csv\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e715717d3912a0a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T23:40:59.872663100Z",
     "start_time": "2025-02-04T23:40:37.346345700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b40e20f9f6b94ffba9f3ed312099f693"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
    "# 여기\n",
    "# model_name=\"../CM1/model/\"+project_name+\"-llama-classifier/checkpoint-525\"   \n",
    "# token_name=\"../CM1/model/\"+project_name+\"-llama-classifier/checkpoint-525\"  \n",
    "max_seq_length = 1024 #2048\n",
    "                                            \n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device,\n",
    "    torch_dtype=compute_dtype,\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, max_seq_length=max_seq_length)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 4\n",
    "\n",
    "# print(tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff3dfea09893b527",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T23:40:59.883664Z",
     "start_time": "2025-02-04T23:40:59.877669100Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(X_test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        try:\n",
    "            prompt = X_test.iloc[i][\"text\"]\n",
    "            pipe = pipeline(task=\"text-generation\", \n",
    "                            model=model, \n",
    "                            tokenizer=tokenizer, \n",
    "                            max_new_tokens = 1, \n",
    "                            temperature = 0.1,\n",
    "                        )\n",
    "            result = pipe(prompt)\n",
    "            answer = result[0]['generated_text'].split(\"<|end_header_id|>\")[-1]\n",
    "            \n",
    "            if \"question\" in answer:\n",
    "                y_pred.append(\"question\")\n",
    "            elif \"feature\" in answer:\n",
    "                y_pred.append(\"feature\")\n",
    "            elif \"bug\" in answer:\n",
    "                y_pred.append(\"bug\")\n",
    "            else: \n",
    "                print(\"없는 레이블?\")\n",
    "                y_pred.append(\"empty\")\n",
    "                # print(result)\n",
    "        except Exception as e:\n",
    "            # print(len(tokenizer(X_test.iloc[i][\"text\"])['input_ids']))\n",
    "            y_pred.append(\"empty\")\n",
    "            # print(e)\n",
    "            print('bug')\n",
    "  \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecde4228618a3895",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T23:40:59.892671Z",
     "start_time": "2025-02-04T23:40:59.883664Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, \n",
    "                             recall_score, \n",
    "                             precision_score, \n",
    "                             f1_score)\n",
    "\n",
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "\n",
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c79a6866ef1403",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-04T23:41:03.995946400Z",
     "start_time": "2025-02-04T23:40:59.891667800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HJE\\anaconda3\\envs\\ICPC-llama-V2\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, dataset_kwargs. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/300 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea490b039e734acea007c9371328b4d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HJE\\anaconda3\\envs\\ICPC-llama-V2\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:413: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# open(\"../CM1/model/\")\n",
    "# output_dir=\"../CM1/model/epoch3/\"+project_name+\"-llama-classifier\"\n",
    "output_dir=\"../CM1/model/0204/\"+project_name+\"-llama-classifier\"\n",
    "# tokenizer.save_pretrained(output_dir)\n",
    "# output_dir=\"facebook_issue_trained_weigths\"\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,                    # directory to save and repository id\n",
    "    # 여기\n",
    "    # num_train_epochs=10,                       # number of training epochs\n",
    "    num_train_epochs=3,                       # number of training epochs\n",
    "    per_device_train_batch_size=1,            # batch size per device during training\n",
    "    gradient_accumulation_steps=1,            # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,                         # log every 10 steps\n",
    "    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n",
    "    group_by_length=False,\n",
    "    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n",
    "    report_to=\"tensorboard\", \n",
    "    # report metrics to tensorboard\n",
    "    #evaluation_strategy=\"steps\",              # save checkpoint every epoch\n",
    "    #load_best_model_at_end = True,\n",
    "    #eval_steps = 25,\n",
    "    #metric_for_best_model = 'accuracy',\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_data,\n",
    "    #eval_dataset=eval_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=max_seq_length,\n",
    "    packing=False,\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,\n",
    "        \"append_concat_token\": False,\n",
    "    },\n",
    "    #compute_metrics=compute_metrics,\n",
    "    #callbacks = [EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ada40901e450f12e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffa6bf51afb445d4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-05T00:36:50.619707800Z",
     "start_time": "2025-02-04T23:41:04.253959800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/225 : < :, Epoch 0.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=225, training_loss=0.4426748106214735, metrics={'train_runtime': 3346.3137, 'train_samples_per_second': 0.269, 'train_steps_per_second': 0.067, 'total_flos': 2.982150146772173e+16, 'train_loss': 0.4426748106214735, 'epoch': 3.0})"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c619ae87c711abc5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-05T00:36:50.631712400Z",
     "start_time": "2025-02-05T00:36:50.620705Z"
    }
   },
   "outputs": [],
   "source": [
    "# trainer.save_model()\n",
    "# tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28783ea3093054e8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-05T00:36:50.698780700Z",
     "start_time": "2025-02-05T00:36:50.624709100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 29992.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "bug\n",
      "Accuracy: 0.333\n",
      "Accuracy for label 0: 0.000\n",
      "Accuracy for label 1: 1.000\n",
      "Accuracy for label 2: 0.000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       100\n",
      "           1       0.33      1.00      0.50       100\n",
      "           2       0.00      0.00      0.00       100\n",
      "\n",
      "    accuracy                           0.33       300\n",
      "   macro avg       0.11      0.33      0.17       300\n",
      "weighted avg       0.11      0.33      0.17       300\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0 100   0]\n",
      " [  0 100   0]\n",
      " [  0 100   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(test_data, model, tokenizer)\n",
    "result=evaluate(y_true, y_pred)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72ceddaa0c1ce81c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-05T00:36:50.699716600Z",
     "start_time": "2025-02-05T00:36:50.654713700Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame({'text': X_test[\"text\"], \n",
    "                           'y_true':y_true, \n",
    "                           'y_pred': y_pred},\n",
    "                          )\n",
    "# evaluation.to_csv(\"../CM1/result/metric/epoch3/\"+project_name+\"_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d08861fec006bd1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-05T00:36:50.700715400Z",
     "start_time": "2025-02-05T00:36:50.660708800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text    y_true y_pred\n",
      "0    <|begin_of_text|><|start_header_id|>system<|en...       bug  empty\n",
      "1    <|begin_of_text|><|start_header_id|>system<|en...       bug  empty\n",
      "2    <|begin_of_text|><|start_header_id|>system<|en...       bug  empty\n",
      "3    <|begin_of_text|><|start_header_id|>system<|en...       bug  empty\n",
      "4    <|begin_of_text|><|start_header_id|>system<|en...       bug  empty\n",
      "..                                                 ...       ...    ...\n",
      "295  <|begin_of_text|><|start_header_id|>system<|en...  question  empty\n",
      "296  <|begin_of_text|><|start_header_id|>system<|en...  question  empty\n",
      "297  <|begin_of_text|><|start_header_id|>system<|en...  question  empty\n",
      "298  <|begin_of_text|><|start_header_id|>system<|en...  question  empty\n",
      "299  <|begin_of_text|><|start_header_id|>system<|en...  question  empty\n",
      "\n",
      "[300 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "487fca6769471d1b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-05T00:36:50.700715400Z",
     "start_time": "2025-02-05T00:36:50.667709200Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f01f88943222c28",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-05T00:36:50.700715400Z",
     "start_time": "2025-02-05T00:36:50.671714100Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb646f4995e19693",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-05T00:36:50.701714400Z",
     "start_time": "2025-02-05T00:36:50.675709100Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICPC-llama-V2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
